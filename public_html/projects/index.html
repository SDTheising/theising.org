<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Projects</title>
    <link rel="stylesheet" href="/css/styles.css">
    <script src="/js/content.js"></script>
</head>
<body>
  <header>
    <div class="top-bar">
      <div class="logo">
        <div style="display: inline-block;">
          <h1 class="brand">Samuel Theising</h1>
          <p>Research Associate @ <a href="https://dorisresearch.com/">DORIS</a></p>
          <p>Eventual Data Scientist</p>
        </div>
      </div>
      <nav>
        <ul>
          <li><a href="/">Home</a></li>
          <li><a href="/about/">About</a></li>
          <li><a href="/projects/">Projects</a></li>
          <li><a href="/blog/">Blog</a></li>
          <li><a href="/contact/">Contact</a></li>
          <li><a href="https://github.com/SDTheising">Github</a></li>
        </ul>
      </nav>
    </div>
  </header>

  <main class="page">
      <section class="quick-links">
        <div class="flex-container">
          <button class="card" onclick="showSection('section1')">
            <h4>Mutual Learning in Machine Learning Algorithms</h4>

            <p><span class="brand">
              My Group Capstone
            </span>
            </p>
          <p>
            A project involving Machine Learning, replicating a prior study from a professor I studied under. 
          </p>
          </button>
          <button class="card" onclick="showSection('section2')">
            <h4>Church Topics Analysis</h4>
            <p>A currently in-progress long-term project involving the collecting of data related to churches and the topics their sermons cover.</p>
            <p>The goal is to identify any trends within the sermons related to topics and congregational size/demographics.</p>
          </button>
          <button class="card" onclick="showSection('section3')">
            <h4>This Website!</h4>
            <p>This website has gone through several iterations, each significantly different. </p>
            <p>I still plan to bring one or two back, but getting up finished was a priority.</p>
          </button>
          <button class="card" onclick="showSection('section4')">
            <h4>My Game(s)</h4>
            <p>I have repeatedly started and stopped game development as I have gone through my career. Here are a few games, either dead or in progress.</p>
          </button>
        </div>
    </section>
    <section class = "flex-container">
      <!-- Content Sections -->
      <div id="section1" class="content-section gallery hidden">
        <!-- Content for Section 1 -->

          <div> 
          <h2>Mutual Learning in Machine Learning Algorithms</h2>

          <hr>

            <div>
              <p dir="ltr" id="docs-internal-guid-37df70f9-7fff-2e78-0716-52b37b04e991">
     <br/>
</p>
<p dir="ltr">
    John Wellspring <br/>
    Bachelors of Science <br/>
    Purdue University <br/>
    Indianapolis, Indiana <br/>
    jwellspr@purdue.edu <br/>
    Samuel Theising <br/>
    Bachelors of Art <br/>
    Purdue University <br/>
    Indianapolis, Indiana <br/>
    theisingsamuel@gmail.com <br/>
    Nassim Zerrouak <br/>
    Bachelors of Science <br/>
    Purdue University <br/>
    Indianapolis, Indiana <br/>
    nzerroua@purdue.edu <br/>
    <br/>
    Zane Smith <br/>
    Bachelors of Science <br/>
    Purdue University <br/>
    Indianapolis, Indiana <br/>
    smithzm@purdue.edu <br/>
</p>
<br/>
<br/>
<br/>
<br/>
<p dir="ltr">
    Abstract—
</p>
<p dir="ltr">
    Mutual learning explores the concept of machine learning, where models such
    as Stochastic Gradient Descent Classifier (SGDC) and Naive Bayes can help
    justify or improve each other's performance by exchanging knowledge during
    training. Data can be explored and understood by the computer’s, leading to
    generalization of News Article classification. This paper will explore how
    mutual learning can be applied to News Article classification and how these
    models can benefit from cross training each other, and how this methodology
    can  produce models that rival the accuracy of those trained on
    significantly larger datasets.
</p>
<br/>
<p dir="ltr">
    Keywords—Machine learning, Mutual learning, Data classification.
</p>
<ol>
    <li dir="ltr">
        <h1 dir="ltr">
            Introduction
        </h1>
    </li>
</ol>
<p dir="ltr">
    This paper discusses the progress made in the creation of a Mutual Learning
    algorithm for the purpose of news classification. It will attempt to
    demonstrate the thought process and development process for both the
    algorithms and codebase.
</p>
<ol start="2">
    <li dir="ltr">
        <h1 dir="ltr">
            Data Preprocessing
        </h1>
    </li>
    <ol>
        <li dir="ltr">
            <h2 dir="ltr">
                General Process
            </h2>
        </li>
    </ol>
</ol>
<p dir="ltr">
    In order to process the data, it would need to be stemmed, lemmatized, and
    tokenized. In order to do this, the open source library SpaCy [1] was used
    in conjunction with NLTK  [5]. The total data was also split into 3 equal
    sized chunks, each being dedicated to a particular model or step. The splits
    were not controlled for equal categorization, despite the chance at improved
    accuracy, to better mimic real-world in which each model may not be provided
    with balanced data.
</p>
<ol start="2">
    <li dir="ltr">
        <p dir="ltr">
            Stemming
        </p>
    </li>
</ol>
<p dir="ltr">
    All of the provided data was stemmed via NLTK [5] before being lemmatized.
    This is done to simplify the data down to its root before returning it to a
    slightly more readable and meaningful form for the analysis.
</p>
<br/>
<ol start="3">
    <li dir="ltr">
        <h2 dir="ltr">
            Lemmatization
        </h2>
    </li>
</ol>
<p dir="ltr">
    The given data, stored in both BBC_train_full and test_data was filtered
    through SpaCy [1] for the purpose of creating readable tokens with any
    extraneous data removed. Items such as numbers and individual letters were
    intentionally saved, as they could prove important to the overall
    classification. The purpose of this is to overall reduce the amount of noise
    in the data and reduce words into their lemma.
</p>
<br/>
<p dir="ltr">
    D.  Tokenization
</p>
<p dir="ltr">
    This data, now parsed down into a more usable format, was then turned into
    individual tokens to be used within the model. This data was then fed into
    the model for both training and testing. Words are now easier to be read and
    seen by the models, allowing for an easier understanding/meaning to the
    data.
</p>
<ol start="3">
    <li dir="ltr">
        <h1 dir="ltr">
            Algorithms
        </h1>
    </li>
</ol>
<p dir="ltr">
    Our project involves implementing two fundamental machine learning
    algorithms for text classification: Naive Bayes and Stochastic Gradient
    Descent Classifier (SGDC). These two models serve as the foundation for the
    initial classification task. In the final stage of our project, we will
    enhance their performance using Mutual Learning, where the two models will
    iteratively share knowledge to improve the overall accuracy. Below, we
    describe the individual algorithms and their role in the mutual learning
    framework:
</p>
<ol>
    <li dir="ltr">
        <h2 dir="ltr">
            Stochastic Gradient Descent
        </h2>
    </li>
</ol>
<p dir="ltr">
    Stochastic Gradient Descent (SGDC) is a supervised learning algorithm that
    can perform both classification and regression. For our project, we are
    using a linear hinge loss SGDC, which works by finding the optimal
    hyperplane that separates different classes in a high-dimensional feature
    space. This model was used to emulate the behavior of a Support Vector
    Machine.
</p>
<ol>
    <li dir="ltr">
        <p dir="ltr">
            Objective:
        </p>
    </li>
</ol>
<p dir="ltr">
    The goal of SGDC is to maximize the margin between the decision boundary
    (hyperplane) and the nearest data points from each class, known as support
    vectors.
</p>
<ol start="2">
    <li dir="ltr">
        <p dir="ltr">
            Steps:
        </p>
    </li>
</ol>
<ul>
    <li dir="ltr">
        <p dir="ltr">
            Convert the tokenized news articles into numerical form using
            TF-IDF.
        </p>
    </li>
    <li dir="ltr">
        <p dir="ltr">
            Train the SGDC model to find the optimal hyperplane that separates
            the categories.
        </p>
    </li>
    <li dir="ltr">
        <p dir="ltr">
            Use the model to classify new, unseen news articles based on the
            learned decision boundary.
        </p>
    </li>
</ul>
<p dir="ltr">
    SGDC is known for its effectiveness in high-dimensional spaces and its
    ability to create complex decision boundaries, making it a strong choice for
    text classification tasks.
</p>
<ol start="2">
    <li dir="ltr">
        <h2 dir="ltr">
            Naive Bayes
        </h2>
    </li>
</ol>
<p dir="ltr">
    The Naive Bayes algorithm is a probabilistic classifier based on Bayes'
    Theorem, with an assumption of independence between the features. Despite
    this simple assumption, Naive Bayes has proven highly effective for text
    classification tasks, particularly when the dimensionality of the data is
    high, as in the case of natural language processing.
</p>
<ol>
    <li dir="ltr">
        <p dir="ltr">
            Assumption:
        </p>
    </li>
</ol>
<p dir="ltr">
    Naive Bayes assumes that all features (words in our case) are independent of
    each other given the class. In text classification, this means that the
    occurrence of a word in an article is independent of the occurrence of other
    words.
</p>
<ol start="2">
    <li dir="ltr">
        <p dir="ltr">
            Steps:
        </p>
    </li>
</ol>
<ul>
    <li dir="ltr">
        <p dir="ltr">
            Preprocess the text data by tokenizing the news articles and
            converting them into a numerical representation using TF-IDF
        </p>
    </li>
    <li dir="ltr">
        <p dir="ltr">
            Calculate the conditional probabilities for each word and classify
            the text into one of the predefined categories (business, politics,
            sports, entertainment, tech) based on the posterior probability
        </p>
    </li>
</ul>
<p dir="ltr">
    Naive Bayes is chosen because of its simplicity, speed, and effectiveness
    with large vocabulary sizes, which are typical in text classification
    problems.
</p>
<ol start="3">
    <li dir="ltr">
        <h2 dir="ltr">
            Mutual Learning Framework
        </h2>
    </li>
</ol>
<p dir="ltr">
    In the final phase of the project, the Naive Bayes and SGDC models will be
    integrated into a Mutual Learning framework. Mutual learning is a
    collaborative learning method where both models can exchange knowledge
    during the training process to enhance performance.
</p>
<ol>
    <li dir="ltr">
        <p dir="ltr">
            Knowledge Sharing:
        </p>
    </li>
</ol>
<p dir="ltr">
    After an initial phase of independent training, the models were given an
    unlabeled dataset and output their predicted labels, along with the
    posterior probability for each one. Based on that information, labels with
    the highest probability were selected, creating a third equal sized data set
    to learn from.
</p>
<ol start="2">
    <li dir="ltr">
        <p dir="ltr">
            Mutual Learning:
        </p>
    </li>
</ol>
<p dir="ltr">
    After the third dataset was created, both models use this to continue their
    training. The combination of the two models' predictions give both extra
    training data, as well as passing along some of the differences in what was
    learned about the classification to the other model.  By leveraging the
    complementary strengths of Naive Bayes (good with probabilistic reasoning)
    and SGDC (good with decision boundaries), we aim to achieve better accuracy
    than either model individually.
</p>
<br/>
<ol start="3">
    <li dir="ltr">
        <p dir="ltr">
            Final Prediction:
        </p>
    </li>
</ol>
<p dir="ltr">
    Following this, each model performed a final stage of retraining against its
    own original labeled data. This process attempts to allow the models to gain
    the strengths of the other, while being given a chance to reinforce its own
    strengths in hopes of not transferring their weaknesses and further refining
    their performance.
</p>
<br/>
<ol start="4">
    <li dir="ltr">
        <h2 dir="ltr">
            Results Before Relearning
        </h2>
    </li>
</ol>
<p dir="ltr">
    Under the current methodology, both SGDC and Naive Bayes perform similarly
    trained off of their respective training sets. Overall, SGDC had an accuracy
    rate of 97 percent, while Naive Bayes had an accuracy rate of 93 percent,
    with most errors occurring in the same two categories: Business and
    Entertainment. Shown below is a comparison of the two, modeled in
    matplotlib. [3]
</p>
<figure>
    <img src="/images/CMSGDClassifier.webp" width="336" height="288" />
    <figcaption>Fig 1. Confusion Matrix for SGDClassifier</figcaption>
    <img src="/images/CMNB.webp" width="336" height="230" />
    <figcaption>Fig 2. Confusion Matrix for Naive Bayes</figcaption>
</figure>
<br/>

<p dir="ltr">
    While there are minor variations throughout, these may arise from the
    differences in the training data, which was not evenly spread across the
    splits, instead having opted for random spreading across the three equal
    sections of training data.
</p>
<p dir="ltr">
    E. Results After Retraining
</p>
<p dir="ltr">
    After we retrained the model following the given algorithm we are retraining
    each of the models by using the allowing both SGDC and Naive Bayes to learn
    off of each other by retaining the overall weaker model. In this step there
    is expected to be an increase in accuracy for both models similar to those
    results of training on the full dataset with labels. Instead of it seeing
    the full dataset it is only getting to see two-thirds of the dataset, with
    one third being self labeled. Again we will be showing the results via
    matplotlib. [3]
</p>

<figure>
        <img src="/images/NVCR.webp" width="336" height="224" />
    <figcaption>Fig 3. Naive Bayes Classification Report</figcaption>
    <img src="/images/SGDCCR.webp" width="336" height="230" />
    <figcaption>Fig 4. SGDC Classification Report/figcaption>
</figure>

<p dir="ltr">
    From the above models there was an increase in accuracy for both models.
    Where we can see jumps in categories that before struggled.
</p>
<ol start="4">
    <li dir="ltr">
        <h1 dir="ltr">
            Conclusion
        </h1>
    </li>
</ol>
<p dir="ltr">
    The methodology presented in this paper successfully achieved its goal of
    producing text classifiers that perform comparably to those trained on
    significantly larger datasets. By leveraging mutual learning, the Naive
    Bayes and SGDC models were able to enhance each other’s performance through
    knowledge sharing and collaborative training. This approach has demonstrated
    its effectiveness as a tool for improving classifier accuracy, particularly
    in scenarios with limited labeled data. Its potential extends to future
    applications, where it can be implemented to boost the performance of
    classifiers across various domains.
</p>
<br/>
<ol>
    <li dir="ltr">
        <p dir="ltr">
            M. Honnibal, I. Montani, S. Van Landeghem, and A. Boyd, "spaCy:
            Industrial-strength natural language processing in Python," 2020.
            [Online]. Available: https://doi.org/10.5281/zenodo.1212303:
            https://github.com/explosion/spaCy
        </p>
    </li>
    <li dir="ltr">
        <p dir="ltr">
            F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O.
            Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J.
            Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and É.
            Duchesnay, "Scikit-learn: Machine learning in Python," *J. Mach.
            Learn. Res.*, vol. 12, pp. 2825-2830, 2011. [Online]. Available:
            https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html
            https://github.com/scikit-learn/scikit-learn
        </p>
    </li>
    <li dir="ltr">
        <p dir="ltr">
            The Matplotlib Development Team, Matplotlib: Visualization with
            Python. [Online]. Available:<a href="https://matplotlib.org/">https://matplotlib.org/</a>. 
            [Accessed: Oct. 4, 2024].
        </p>
    </li>
    <li dir="ltr">
        <p dir="ltr">
            Chowdhury, S.T., Kumpati, N.S., Mukhopadhyay, S. (2024). Mutual
            Learning for News Classification. In: Arai, K. (eds) Intelligent
            Systems and Applications. IntelliSys 2024. Lecture Notes in Networks
            and Systems, vol 1066. Springer, Cham.
            https://doi.org/10.1007/978-3-031-66428-1_3/.
        </p>
    </li>
    <li dir="ltr">
        <p dir="ltr">
            S. Bird, E. Klein, and E. Loper, Natural Language Processing with
            Python: Analyzing Text with the Natural Language Toolkit.
            Sebastopol, CA, USA: O'Reilly Media, Inc., 2009. [Online].
            Available: https://www.nltk.org/book/
        </p>
    </li>
</ol>
<br/>
<br/>
<p dir="ltr">
    Our Github:
</p>
<p dir="ltr">
    https://github.com/49500/495CapstoneProject
</p>

            </div>

         </div>
      </div>
      <div id="section2" class="content-section gallery hidden">
        <!-- Content for Section 2 -->
         <div class = "flex-container">
          <img style="width: 100%; height: 100%;" src="/images/CSVofChurches.webp" alt="Image of CSV" />
         </div>
         
          <div> 
          <h2>Church Topics Analysis</h2>

          <hr>

          <p>
                This project was started with a question I asked after moving churches several times: 
                How does congregation size and denomination affect the topics covered in sermons.
          </p>
          <p>
                My hypothesis is that the topics will get more negative, and more related to end times, with decreasing congregation size.
          </p>

          <br>

          <p>
                To start, I found a website that aggregates churches for people looking for their next one.
                This website also very helpfully contained information such as denomination and approximate congregation size.
          </p>
          <p>
                After scraping through the site, I came away with around 1,000 total churches in my local area, which I chose to limit the scope of my project to.
                I additionally needed to scrape each site individually for links to their sermons. I figured the more direct way would be to find youtube links, as many
                churches began hosting their own weekly livestreams during the covid-19 lockdowns.
          </p>

          <br>

          <p>
                This is the state the project has currently found itself in, I have a small MongoDB database set up (I wanted to try it out after using purely relational databases in the past) 
                and I am working on perfecting my web scraper so it won't take days to get through every website. 
          </p>

          <p>
                The next step is to pull transcripts of each sermon from their respective youtube videos, parse and lemmatize them, and then place it all into my database for further analysis.
          </p>

          <p>
                I plan to use sentiment analysis to determine whether the sermon is mainly positive or negative, as well as using the techniques I gained from my previous project 
                Mutual Learning in Machine Learning Algorithms, to sort them into categories based on the overall topics. 
          </p>
         </div>
      </div>
      <div id="section3" class="content-section gallery hidden">
        <!-- Content for Section 3 -->
         <div class = "flex-container">
          <img src="/images/theising_org_old.webp" alt="Old Website/Future Website" />
          <img src="/images/theising_org_070925.webp" alt="Current Website!" />
          </div>

          <div> 
          <h2>This Website.</h2>

          <hr>
          
          <h3>The Early Days</h3>

          <p>
            I truly wanted my portfolio website to be something special. I had grand plans, a retro-istic website where the UI looked like something plucked out of an early 80's
            video game. Well, an 80's game portrayed in a movie from the 2010's, I don't know that any really had the look I wanted.
          </p>
          <p>
            It would be fully 3D rendered, with wireframe folders for navigation and pages that would be styled the same. 
            Unfortunately, this was eating up too much of my time. I really, really needed to just get something out there, and trying to make my design work in an unfamiliar system (Three.js)
            was simply too slow, especially considering I equally needed to get content up for the site, not just a framework.
          </p>

          <h3>Nowadays</h3>

          <p>
            Thus, here we are. With a simplistic primarily HTML and CSS website to host what I've been up to. I still plan to implement what I truly wanted, but 
            that has been placed on the backburner, along with so many other projects. 
          </p>

          <p>
            You can still visit the site I really wanted to make <a href="https://threed.theising.org">here</a> though! 
            It is very unfinished, but perhaps you can see the vision.
          </p>
         </div>
      </div>
      <div id="section4" class="content-section gallery hidden">
        <!-- Content for Section 4 -->
         <div class = "flex-container">
          <img src="/images/solitaire.webp" alt="Solitaire" />
          <img src="/images/mecha_leg.webp" alt="Mecha Leg" />


          </div>

          <div> 
          <h2>My Games</h2>

          <hr>

          <h3>Solitaire</h3>
          <p>
            This is both the newest and most simplistic. Born of one simple desire: To play Solitaire on my phone, without advertisements, for free. 
          </p>

          <p>
            There has been some progress, but it only began within the past week as of writing, so progress is minor. 
            I have never worked on a 2d game before, so progress is also very much a learning experience.
          </p>

          <p>
            In the current state, there are 52 cards, each one properly textured, shuffled, and laid out for a game. They can also be dragged about. 
          </p>

          <p>
            Still to be added is the ability to place cards on top of each other in the correct order, as well as remove them from the game by stacking them on their respective suits.
          </p>


          <h3>Unnamed Mecha Game</h3>

          <p>
            I have been slowly building up a shared world. This world contains all of the characters I have made up throughout my life, a constant hobby. 
            This is the setting of the game, one which I intend to be the first opening into the world that I share, aside from some small writings I have put out.
          </p>

          <p>
            Unfortunately, this one is even less finished than the Solitaire. I am learning 3D modeling at the moment, and have put a pause on the software development side until I have at least a few assets completed.
          </p>

         </div>
      </div>
      <div id="section5" class="content-section gallery hidden">
        <!-- Content for Section 5 -->
         <div class = "flex-container">
          <img src="https://placehold.co/600x400?text=Section+5" alt="Project 5" />
          <img src="https://placehold.co/600x400?text=Section+5" alt="Project 5" />
          <img src="https://placehold.co/600x400?text=Section+5" alt="Project 5" />
          </div>


          <div> 
          <h2>Lorem ipsum dolor.</h2>

          <hr>

          <p>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. 
            Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. 
            Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. 
            Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
          </p>
         </div>
      </div>
    </section>

    <section class="container content-section">
      <h2 class="brand">Project Gallery</h2>
      <div class="gallery">
        <img src="/images/deepnn baller.webp" alt="Deep Neural Network Confusion Matrix" />
        <img src="/images/output.webp" alt="Roly Poly Game" />
        <img src="/images/sem1proj.webp" alt="Project from first semester of college." />
      </div>

      
    </section>
  </main>

  <footer>
    <div class="footer-content">
      <p>&copy; 2025 <span class="brand">Samuel Theising</span> - All Rights Reserved.</p>
    </div>
  </footer>
</body>
</html>
